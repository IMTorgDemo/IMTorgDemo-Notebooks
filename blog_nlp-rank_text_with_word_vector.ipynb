{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking Text With Word Embeddings\n",
    "Date: 2020-02-20  \n",
    "Author: Jason Beach  \n",
    "Categories: MachineLearning, DataScience, Mathematics  \n",
    "Tags: nlp, classification  \n",
    "<!--eofm-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I recently implemented search functionality for my Hugo site, which can be seen at: https://imtorgdemo.github.io/pages/search/.  The search uses lunr.js, an implementation of Solr.   While it works, sufficiently, the metadata used for ranking queries could be improved.  It would also be nice to visually locate the results by where resulting posts fit into the three data science fundamental disciplines: mathematics, computer science, and business.  This narrative provides a quick solution for ranking posts by each discipline, then reducing the dimensions to 3 axes in the xy-plane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment \n",
    "\n",
    "Lets setup the environment for the basic scientific and NLP work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(\"This is a sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blog_test-my_first_post.md', 'blog-logic_for_math.md']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir('./Data/markdown')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/jovyan/PERSONAL/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the basic metadata for each post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+++\n",
      "title = \"Building Math from the Ground-Up\"\n",
      "date = \"2019-07-05\"\n",
      "author = \"Jason Beach\"\n",
      "categories = [\"Mathematics\", \"Logic\"]\n",
      "tags = [\"nlp\", \"tag2\", \"tag3\"]\n",
      "+++\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! head Data/markdown/blog-logic_for_math.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a post that focuses primarily on mathematics.  So, we expect the ranking results to align with mathematics more than the other two fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/jovyan/PERSONAL/Data/markdown/blog-logic_for_math.md\"\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = lines[1:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = '  '.join(data[9:])\n",
    "content = content.replace(\"\\n\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "\n",
    "pattern = re.compile(r'([^\\s\\w]|_)+')\n",
    "content = pattern.sub('', content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = ' '.join(content.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get word assocations from website.  This is performed manually.  In the future, scrape the site and get many more assocations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO:scrape the website\n",
    "import requests\n",
    "\n",
    "url = 'https://wordassociations.net/en/words-associated-with/TARGET?button=Search'\n",
    "url = url.replace('TARGET','computer')\n",
    "resp = requests.get(url)\n",
    "\n",
    "noun_loc = resp.text.find('Noun')\n",
    "resp.text.find('Adjective')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search: business\n",
    "word_assoc_biz = 'MbaEntrepreneurshipRetailEntrepreneurConsultancyStartupAccountingSectorMarketingBankingCateringGroceryInvestingWhartonEnterpriseLendingStakeholderCustomerEconomicFinanceConsumerCommerceConglomerateEconomicsBakeryInvestmentInsuranceManagementSupplierMarketplaceInvestorVentureFirmTelecomTradesmanPayrollManufacturingBrokerTransactionLumberRetailerProfitFinancingContractingSustainabilityPartnerInnovationHospitalityNetworkingAccountantExecutiveIncentivePartnershipProcurementShareholderEmployeeAssetUndergraduateIndustrialPhilanthropyEquityLiabilitySmallAdvertisingInformaticsSalesTourismRecessionLeisurePurchasingConsultantOwnerHaasAccreditationMercantileWholesaleProfitableLucrativeUnfinishedRetailThrivingRiskyConsultingCorporateMultinationalBoomingNonprofitGraduateAccreditedPhilanthropicFinancialSustainableAutomotiveBankruptUrgentDiversifyDivestInvestProsperRestructure'\n",
    "tmp = re.findall('[A-Z][^A-Z]*', word_assoc_biz)\n",
    "words_biz = ' '.join(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search: software, programming\n",
    "word_assoc_cs = 'SimulcastOptimizationDualityIntegerSynthesizerApiSynthNewscastKeyboardCwProgrammerCompilerPythonBasicKeywordAiringAffiliateSyndicationDecompositionAlgorithmJavaUhfUnixSemanticsParadigmInterfaceRecourseConstraintArrangerAutomatonFccPascalSyntaxBroadcastingBroadcastCbcNickelodeonApproximationNetworkAffiliationPbsSemanticRelaxationInstrumentationLineupHdBrandingLanguagePercussionEmmyLogicFmIdeAbcChannelTelecastDrumCableForthBbQuadraticStochasticNonlinearWeekdayFractionalOrientedLinearConvexJavaOptimalDynamicSequentialDaytimeScriptedConcurrentConstrainedPrimalConcaveImperativeGraphicalRetroProceduralAiredObjectiveFuzzyAnalogPolynomialSyndicateAirNetworkProgrammeBroadcastGeneralizeStructureRelaunchMixnuHardwareLinuxCadPackageDeveloperMacintoshVendorWorkstationUnixAutomationProgrammerAmigaEncryptionFunctionalityServerVisualizationBrowserIbmAdobeCompatibilityComputerOsComputingAtariPcApiGuiInterfaceUserGraphicsNetworkingLicenseSimulationRepositoryModelingXpMidiModemUpdateVerificationRouterCompilerToolProcessorEditingSimulatorMultimediaApplicationProviderLaptopUpgradeCpuNokia3dMetadataMicroprocessorApacheStartupPiracyAppIntelValidationSuiteOptimizationCiscoKernelModellingDocumentationGraphicHackerImplementationConsultancyVulnerabilityTcpEmailGps'\n",
    "tmp = re.findall('[A-Z][^A-Z]*', word_assoc_cs)\n",
    "words_cs = ' '.join(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search: mathematics\n",
    "word_assoc_math = 'PhysicAlgebraMathematicCalculusMathematicianPhysicsGeometryOlympiadAstronomyHilbertTopologyGraderPolynomialManifoldProficiencyInformaticsBscTheoremAxiomEulerMathMechanicPhdGeneralizationIntegralAptitudeProfessorshipGenealogyBsChemistryTextbookStatisticEmeritusComputationSpringerLogicDescartesDoctorateScienceMechanicsCurriculumMultiplicationBachelorProfessorUndergraduateSubgroupIntegerConjectureNeumannGraduateComputingLecturerSummaBiologySubsetAstrologyFourierExamPedagogyCantorTensorPhilosophyCalculatorPermutationMatriceAlgebraicMathematicalTopologicalProjectiveProficientEuclideanArithmeticAppliedDifferentialManifoldDiscreteOrthogonalComputationalAnalyticPolynomialInvariantNumericalGeometricFiniteQuadraticStochasticGradeGeometricalStudiedSymmetricBabylonianTheoreticalDegreeAbstractTextbookEmeritusGraduate'\n",
    "tmp = re.findall('[A-Z][^A-Z]*', word_assoc_math)\n",
    "words_math = ' '.join(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Data/markdown/'\n",
    "file = path + 'word_assocation_ref.json'\n",
    "words = {\"math\": words_math, \"cs\": words_cs, \"biz\": words_biz}\n",
    "\n",
    "import json\n",
    "with open(file, 'w') as fp:\n",
    "    json.dump(words, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file, 'r') as fp:\n",
    "    new_words = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "math = nlp(words_math)\n",
    "cs = nlp(words_cs)\n",
    "biz = nlp(words_biz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results use the cosine similarity between the fields and all the word-embeddings of terms in the document.  They are not what we expect to see because math is ranked lowest, despite the document using math as the primary subject.  \n",
    "\n",
    "We can probably do better by removing unneccessary stop words and taking the most 'important' words in the document.  The most important terms can be defined using the TF-IDF formula that is typical in 'bag-of-words' NLP approaches.\n",
    "\n",
    "We will use the `sklearn` library for the simple calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5729121134078637\n",
      "0.6058354478834562\n",
      "0.48928262314068244\n"
     ]
    }
   ],
   "source": [
    "# Compare two documents\n",
    "doc1 = nlp(content)\n",
    "print(doc1.similarity(biz))\n",
    "print(doc1.similarity(cs))\n",
    "print(doc1.similarity(math))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=3, analyzer='word', stop_words = 'english', sublinear_tf=True)\n",
    "tfidf.fit(content.split(' '))\n",
    "feature_names = tfidf.get_feature_names()\n",
    "\n",
    "def get_ifidf_for_words(text):\n",
    "    tfidf_matrix= tfidf.transform([text]).todense()\n",
    "    feature_index = tfidf_matrix[0,:].nonzero()[1]\n",
    "    tfidf_scores = zip([feature_names[i] for i in feature_index], [tfidf_matrix[0, x] for x in feature_index])\n",
    "    return dict(tfidf_scores)\n",
    "\n",
    "scores = get_ifidf_for_words(content)\n",
    "sorted_scores = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the choosing important words by TF-IDF look much more promising.  These are words you would expect to be associated with formal mathematics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('logic', 0.14527847977675443),\n",
       " ('logical', 0.140443796477262),\n",
       " ('form', 0.13793934097017202),\n",
       " ('predicate', 0.13687559493415327),\n",
       " ('use', 0.1342685066335781),\n",
       " ('language', 0.13265636975548645),\n",
       " ('symbols', 0.13265636975548645),\n",
       " ('truth', 0.13265636975548645),\n",
       " ('argument', 0.13077412529085744),\n",
       " ('inference', 0.13077412529085744)]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "take(10, sorted_scores.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 82 words that are most important in describing the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(sorted_scores.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we compare the document's most important words against the fields' associations we find a much more compelling story.  Now, Math is ranked the highest.  Computer science is not far behind, but Business is rightfully quite different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5238546677925497\n",
      "0.6606328549347019\n",
      "0.6888387753219556\n"
     ]
    }
   ],
   "source": [
    "# Compare documents\n",
    "words = ' '.join(list(sorted_scores.keys()))\n",
    "doc1 = nlp(words)\n",
    "print(doc1.similarity(biz))\n",
    "print(doc1.similarity(cs))\n",
    "print(doc1.similarity(math))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to visually locate the document within a svg image that can be seen, below.  This is quite unintuitive because the there are three axes within a 2D-plane.  We must reduce the three dimensions to two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/img-datascience_plain.svg\" alt=\"datascience\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no correct answer to this.  In fact, there are approaches we could have taken, earlier, that would have completed this for us.  A supervised clustering approach could have ensured the three groups.\n",
    "\n",
    "But, we are keeping this simple and fast - no modeling.  Instead of justifying a best solution, let us find the simplest method to reduce dimensions which is NOT incorrect.  We can make the following assumptions:\n",
    "\n",
    "* While the `similarity()` method returns cosine similarity with a range of 0-no similarity and 1-perfect similarity, the similarity in writing style leads us to expect an actual range of .50-.70\n",
    "* x-dimension: Computer Science and Mathematics are antagonistic to each other (in a technical field perspective), but on a continuous scale between the two, so the two should be subtracted\n",
    "* y-dimension: Business is discrete in it is addressed in the text, or not\n",
    "\n",
    "We can use the [generalized logistic function](https://en.wikipedia.org/wiki/Generalised_logistic_function) with subtracting Computer Science from Math, and say 0 is completely a CS paper, while 1 is completely a Math paper.  We use an arbitrary B=25 to ensure a steep difference between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6681877721681656\n"
     ]
    }
   ],
   "source": [
    "#formula: Y = A + (K-A)/(C+Q*np.exp(-B*t))^1/v\n",
    "# set A and B, with all other parameters set to 1\n",
    "\n",
    "def general_logistic(Beta, cs, math):\n",
    "    t = math - cs\n",
    "    return (1/(1+np.exp(-B*t)))\n",
    "\n",
    "xPt = general_logistic(25, .660, .688)\n",
    "print( xPt )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the actual range is closer to .50-.70, we can expect .60 to be decisive line with value greater than meaning applicability.  So, the y-axis will be 0-top and 1-bottom, with the top of the Business set at .60.  A similarity value lower than this number means the paper is not in this set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5238546677925497\n"
     ]
    }
   ],
   "source": [
    "yPt = doc1.similarity(biz)\n",
    "print( yPt )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/img-datascience_drawing.png\" alt=\"datascience\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototype\n",
    "\n",
    "Lets complete the prototype with some frontend work using D3js."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "BizPt = doc1.similarity(biz)\n",
    "CsPt = doc1.similarity(cs)\n",
    "MathPt = doc1.similarity(math)\n",
    "\n",
    "xPt = general_logistic(25, CsPt, MathPt)\n",
    "yPt = BizPt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.insert(4, f\"location = [{xPt}, {yPt}]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['+++\\n',\n",
       " 'title = \"Building Math from the Ground-Up\"\\n',\n",
       " 'date = \"2019-07-05\"\\n',\n",
       " 'author = \"Jason Beach\"\\n',\n",
       " 'location = [0.6693281622812353, 0.5238546677925497]',\n",
       " 'categories = [\"Mathematics\", \"Logic\"]\\n',\n",
       " 'tags = [\"nlp\", \"tag2\", \"tag3\"]\\n',\n",
       " '+++\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = ''.join(metadata) + content\n",
    "\n",
    "file_path = \"/home/jovyan/PERSONAL/Data/markdown/result.md\"\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the transformed data exported to markdown files, it can be indexed by lunrJs.  The results of the search query can load both the post information, and the location can be used with the svg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "beakerx.point = {\"xPt\":xPt, \"yPt\":yPt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beakerx.object import beakerx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require.config({\n",
       "  paths: {\n",
       "      d3: '//cdnjs.cloudflare.com/ajax/libs/d3/4.9.1/d3.min'\n",
       "  }});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "require.config({\n",
    "  paths: {\n",
    "      d3: '//cdnjs.cloudflare.com/ajax/libs/d3/4.9.1/d3.min'\n",
    "  }});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "beakerx.displayHTML(this, '<div id=\"fdg\"></div>');\n",
       "\n",
       "var point = beakerx.point\n",
       "\n",
       "\n",
       "\n",
       "var d3 = require(['d3'], function (d3) {\n",
       "    \n",
       "    var width = 300,\n",
       "        height = 200;\n",
       "\n",
       "    var svg = d3.select(\"#fdg\")\n",
       "                .append(\"svg\")\n",
       "                .attr(\"width\", width)\n",
       "                .attr(\"height\", height)\n",
       "                .attr(\"transform\", \"translate(\"+[100, 0]+\")\")\n",
       "\n",
       "    var node = svg\n",
       "          .append(\"circle\")\n",
       "          .attr(\"class\", \"dot\")\n",
       "          .attr(\"r\", 10)\n",
       "          .attr(\"cx\", 150)\n",
       "          .attr(\"cy\", 100) \n",
       "          .style(\"fill\", \"Blue\");\n",
       "\n",
       "    \n",
       "//setup-x \n",
       "var xValue = function(d) { return d.xPt;},           // data -> value\n",
       "    xScale = d3.scale.linear().range([0, width]),    // value -> display\n",
       "    xMap = function(d) { return xScale(xValue(d));}, // data -> display\n",
       "    xAxis = d3.svg.axis().scale(xScale).orient(\"bottom\");\n",
       "\n",
       "    \n",
       "  //x-axis\n",
       "  svg.append(\"g\")\n",
       "      .attr(\"class\", \"x axis\")\n",
       "      .attr(\"transform\", \"translate(0,\" + height + \")\")\n",
       "      .call(xAxis)\n",
       "    .append(\"text\")\n",
       "      .attr(\"class\", \"label\")\n",
       "      .attr(\"x\", width)\n",
       "      .attr(\"y\", -6)\n",
       "      .style(\"text-anchor\", \"end\")\n",
       "      .text(\"Calories\");    \n",
       "    \n",
       "});   \n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "beakerx.displayHTML(this, '<div id=\"fdg\"></div>');\n",
    "\n",
    "var point = beakerx.point\n",
    "\n",
    "\n",
    "\n",
    "var d3 = require(['d3'], function (d3) {\n",
    "    \n",
    "    var width = 300,\n",
    "        height = 200;\n",
    "\n",
    "    var svg = d3.select(\"#fdg\")\n",
    "                .append(\"svg\")\n",
    "                .attr(\"width\", width)\n",
    "                .attr(\"height\", height)\n",
    "                .attr(\"transform\", \"translate(\"+[100, 0]+\")\")\n",
    "\n",
    "    var node = svg\n",
    "          .append(\"circle\")\n",
    "          .attr(\"class\", \"dot\")\n",
    "          .attr(\"r\", 10)\n",
    "          .attr(\"cx\", 150)\n",
    "          .attr(\"cy\", 100) \n",
    "          .style(\"fill\", \"Blue\"); \n",
    "    \n",
    "});   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The final result of the script and D3 can be at: https://imtorgdemo.github.io/pages/search/."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
