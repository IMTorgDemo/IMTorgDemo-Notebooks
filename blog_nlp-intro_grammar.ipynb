{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b81de21-ffb5-4001-b812-839dfa1f92f3",
   "metadata": {},
   "source": [
    "# Grammar Refresher and Rule-Based Models for NLP\n",
    "\n",
    "Date: 2023-03-06  \n",
    "Author: Jason Beach  \n",
    "Categories: Introduction_Tutorial, Data_Science  \n",
    "Tags: nlp, grammar, rule-based_models, spacy\n",
    "\n",
    "<!--eofm-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcab9da2-e66c-4b44-9779-72b1e84b8e7c",
   "metadata": {},
   "source": [
    "Grammar and rule-based models are some of the most neglected areas of study for NLP practicitioners.  Most programmers are taking the FANG approach to NLP: more data and bigger models.  This is prohibitively expensive on many projects, and can be much less effective when you have a good understanding and scope in a classification problem.  In this post, we will provide a grammar refresher and see how it corresponds to python's SpaCy module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90d96c-8ee0-42fc-8d80-096dabc45cdc",
   "metadata": {},
   "source": [
    "## Configure Environment\n",
    "\n",
    "Lets get some tools and a sample of sentences that we can use, later."
   ]
  },
  {
   "cell_type": "raw",
   "id": "009b884d-921d-4cf0-a142-ca2f24025f00",
   "metadata": {
    "tags": []
   },
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a7149c3-6e76-4b48-ab63-e6eae2db0343",
   "metadata": {
    "tags": []
   },
   "source": [
    "! pip install spacy"
   ]
  },
  {
   "cell_type": "raw",
   "id": "90707359-8c53-4fa5-a93c-0acd77efd488",
   "metadata": {
    "tags": []
   },
   "source": [
    "! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5c1981e-e547-4d67-bea2-7059550714ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b742c2d-0ab6-48fc-a36c-b767a18f4296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0fd861f6-b611-44ef-9445-082cd1371ea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96f24403-f32e-42ea-a48c-7790e9eaa94c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('popular')\n",
    "nltk.corpus.gutenberg.fileids()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba97cef8-68db-459a-94a8-e64a6e26fe0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw = nltk.corpus.gutenberg.raw('melville-moby_dick.txt')\n",
    "spaces = raw.replace('\\n\\n',' ').replace('\\n',' ').replace('\\r',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1d38c0c-6bd4-43b3-baad-87ba436c30d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_RE_COMBINE_WHITESPACE = re.compile(r\"\\s+\")\n",
    "corpus = _RE_COMBINE_WHITESPACE.sub(\" \", spaces).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9affeff3-2672-4459-819f-13ddf85af073",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus' characters: 1,211,073\n"
     ]
    }
   ],
   "source": [
    "lcorp = len(corpus)\n",
    "print(f\"corpus' characters: {format(lcorp,',d')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7142366-c0e9-4936-8451-9d21cf4c60bb",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "Using examples from 'The Little Brown Handbook' and 'Linguistics Useful for NLP'.\n",
    "\n",
    "Modules used:\n",
    "    * [spacy-pattern-builder]()\n",
    "    * [spacy role pattern]()\n",
    "    * [styled text]()\n",
    "    \n",
    "    \n",
    "Blog references:\n",
    "    * [neural coreferences](https://explosion.ai/blog/coref)\n",
    "    * [applied nlp thinking](https://explosion.ai/blog/applied-nlp-thinking)\n",
    "    * [statistical nlp](https://explosion.ai/blog/eli5-computers-learn-reading)\n",
    "    * [basic pos tagger](https://explosion.ai/blog/part-of-speech-pos-tagger-in-python)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec253ba0-8396-441e-a4c1-217ae45fcaaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sents = [\"Art can be controversial.\",\n",
    "         \"It has caused disputes in Congress and in artists' studios.\",\n",
    "         \"The earth trembled.\",\n",
    "         \"The earthquake destroyed the city.\",\n",
    "         \"The result was chaos.\",\n",
    "         \"The government sent the city aid.\",\n",
    "         \"The citizens considered teh earthquake a disaster.\"\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91296d65-8bef-4c31-a8e6-b668594a4b69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
